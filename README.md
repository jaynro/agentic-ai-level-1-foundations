
# Project 1 ‚Äì The Fact-Checking Auditor (Finance)

## Overview
The Fact-Checking Auditor is an AI agent designed to automate the verification of factual claims in financial documents. Given a piece of text (e.g., a section of an annual report or bullet-point claims), the agent identifies key factual statements and checks them against reliable external sources. It outputs an **Audit Report** that labels each claim as True, False, or Not Sure, with evidence citations.

- **Domain:** Finance (financial reports, news, numeric data)
- **Key Techniques:** Retrieval-Augmented Generation (RAG), LLM prompt engineering, single-agent reasoning
- **ADK Focus:** `LlmAgent` with tool usage (no complex chaining)

By automating fact-checking, organizations like banks, investment firms, or regulators can reduce manual effort and errors.

## Features
- **Automated Claim Extraction** ‚Äì Parses input text to isolate factual statements.
- **Web/Data Retrieval** ‚Äì Performs searches to fetch evidence.
- **AI Verification** ‚Äì Uses an LLM (e.g. Google Gemini) to classify each claim with reasoning.
- **Report Generation** ‚Äì Produces Markdown/text reports with verdicts and references.
- **Iterative Check (optional)** ‚Äì One retry with refined queries if initial results are unclear.

_No frontend included ‚Äì console or Jupyter interaction only._

---

## Installation and Setup

### 1. Clone Repository
Ensure the following files are present:
- `fact_auditor.py` (main script)
- `search_tool.py` (search module)
- `README.md`, `SPEC.md`

### 2. Install Dependencies
```bash
pip install google-generativeai google-adk requests python-dotenv

```

### 3. Configure API Keys

Create a `.env` file in project root:

```bash
GOOGLE_API_KEY=<YOUR-PALM-API-KEY>
SEARCH_API_KEY=<YOUR-SEARCH-API-KEY>
SEARCH_API_URL=<endpoint-URL-if-needed>

```

### 4. Configuration Options

Edit `fact_auditor.py` if needed:

* `MAX_SEARCH_RESULTS`
* `CONFIDENCE_THRESHOLD`
* Input/output file paths

---

## Usage

### Option 1: From File

```bash
python fact_auditor.py --input sample_claims.txt

```

Generates `audit_report.md` by default.

### Example Output

```markdown
1. **Claim:** "Q4 2025 revenue increased by 15%."
   **Verdict:** ‚úÖ Verified. *Official statement reports 16%.* „ÄêSource: Q4 2025 Report„Äë

2. **Claim:** "XYZ acquired ABC in 2022 for $5B."
   **Verdict:** ‚ùå False. *No evidence of acquisition in 2022.* „ÄêSource: SEC Filings„Äë

3. **Claim:** "2023 inflation rate was 4%."
   **Verdict:** üî∂ Not Sure. *Conflicting reports: 3.8%‚Äì4.1%.* „ÄêSource: IMF Data„Äë

```

### Option 2: Interactive Mode

```python
from fact_auditor import FactCheckingAgent
agent = FactCheckingAgent()
text = "Acme revenue up 20% in Q3. CEO is Jane Doe."
report = agent.verify_text(text)
print(report)

```

---

## Project Structure

```
project1-fact-checker/
‚îú‚îÄ‚îÄ fact_auditor.py
‚îú‚îÄ‚îÄ search_tool.py
‚îú‚îÄ‚îÄ report_formatter.py (optional)
‚îú‚îÄ‚îÄ sample_claims.txt
‚îú‚îÄ‚îÄ SPEC.md
‚îî‚îÄ‚îÄ README.md

```

---

## How it Works

The system operates on a linear `Extract ‚Üí Verify ‚Üí Output` pipeline, leveraging Google ADK principles for tool management.

```mermaid
graph TD
    %% Inputs
    InputDoc[üìÑ Input Document/Text] --> Extract[üîç Extract Factual Claims]

    %% The Core Logic
    subgraph "Fact-Checking Agent"
        Extract -->|List of Claims| LoopStart{For Each Claim}
        
        LoopStart -->|1. Generate Query| Query[‚ùì Formulate Search Query]
        Query -->|2. Search External Data| SearchTool[üåê Search Tool / API]
        
        SearchTool -->|3. Return Evidence| Compare[üß† LLM Analysis]
        Compare -->|Compare Claim vs. Evidence| Verdict{Verdict?}
        
        Verdict -- "Matches" --> V_True[‚úÖ Verified]
        Verdict -- "Conflicts" --> V_False[‚ùå False]
        Verdict -- "Insufficient Data" --> V_Unsure[üî∂ Not Sure]
        
        V_True & V_False & V_Unsure --> Accumulate[üìù Log Result]
        Accumulate --> LoopStart
    end

    %% Output
    LoopStart -- "All Claims Processed" --> Report[üìä Generate Final Audit Report]

    %% Styling
    classDef input fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef process fill:#fff9c4,stroke:#fbc02d,stroke-width:2px;
    classDef tool fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px;
    classDef output fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px;

    class InputDoc input;
    class Extract,Query,Compare,Verdict,Accumulate,LoopStart process;
    class SearchTool tool;
    class Report,V_True,V_False,V_Unsure output;

```

1. **Splits input** into atomic factual claims.
2. **Searches evidence** using `SearchTool` (Web or internal DB).
3. **LLM evaluates** the claim against the retrieved evidence.
4. **Generates report** with verdicts and references.

---

## Example Scenario

**Use Case:** Auditing a press release.

* Claim: "Acme won the XYZ Award in 2025." ‚Üí ‚ùå False (found other winner).
* Claim: "Revenue grew 50% in 2024." ‚Üí ‚úÖ Verified (via financial report).

---

## Limitations & Improvements

* **Knowledge Cutoff:** May miss very recent/proprietary data.
* **Reasoning Limits:** Doesn‚Äôt support multi-claim logic yet.
* **Language Support:** English only (for now)

